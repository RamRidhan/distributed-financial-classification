{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "VLSOnLZeEX_C",
      "metadata": {
        "id": "VLSOnLZeEX_C"
      },
      "source": [
        "---\n",
        "# **Dynamic Classification of S&P 500 Stocks Using Distributed Computing and Fundamental Ratios**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6z_4FNiIEOvL",
      "metadata": {
        "id": "6z_4FNiIEOvL"
      },
      "source": [
        "\n",
        "\n",
        "## **ST446 GROUP PROJECT**\n",
        "## **CANDIDATE NUMBERS:** 50714, 49775,49663, 49872\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y_CD8OsUD9zb",
      "metadata": {
        "id": "y_CD8OsUD9zb"
      },
      "source": [
        "**NOTE FOR EVALUATOR:**\n",
        "\n",
        "---> **Dataset link is uploaded in a pdf file named ST446 DATASET LINK.pdf file**\n",
        "\n",
        "--> **Our final dataset can be found in three solution notebooks uploaded in a folder named ST446 GROUP PROJECT SOLUTION**\n",
        "\n",
        "--> **Data Preprocessing steps are done in main solution files [ 3 solution files ]**\n",
        "\n",
        "--> **Here we had used api keys and different methods for api extraction for extracting macro economic data. For fundamental data we directly downloaded from bloomberg by choosing our parameters based on our project objective.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "J9o1u761D8yb",
      "metadata": {
        "id": "J9o1u761D8yb"
      },
      "source": [
        "---\n",
        "## **DATA EXTRACTION**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "giYSed0xD9ws",
      "metadata": {
        "id": "giYSed0xD9ws"
      },
      "source": [
        "---\n",
        "### **WE USED SOURCES FROM:**\n",
        "\n",
        "\n",
        "*   **FRED API - FOR MACRO DATA**\n",
        "*   **BLOOMBERG - FUNDAMENTAL DATA**\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34329459",
      "metadata": {
        "id": "34329459",
        "outputId": "fba1122c-ba80-413a-fb66-b34cfa50f606",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fredapi in /opt/conda/miniconda3/lib/python3.11/site-packages (0.5.2)\n",
            "Requirement already satisfied: pandas in /opt/conda/miniconda3/lib/python3.11/site-packages (from fredapi) (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas->fredapi) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas->fredapi) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas->fredapi) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas->fredapi) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->fredapi) (1.17.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: yfinance in /opt/conda/miniconda3/lib/python3.11/site-packages (0.2.58)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from yfinance) (2.1.4)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from yfinance) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.31 in /opt/conda/miniconda3/lib/python3.11/site-packages (from yfinance) (2.31.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /opt/conda/miniconda3/lib/python3.11/site-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from yfinance) (3.10.0)\n",
            "Requirement already satisfied: pytz>=2022.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /opt/conda/miniconda3/lib/python3.11/site-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from yfinance) (3.18.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from yfinance) (4.13.4)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /opt/conda/miniconda3/lib/python3.11/site-packages (from yfinance) (0.10.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.13.2)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from curl_cffi>=0.7->yfinance) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from curl_cffi>=0.7->yfinance) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests>=2.31->yfinance) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests>=2.31->yfinance) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests>=2.31->yfinance) (1.26.18)\n",
            "Requirement already satisfied: pycparser in /opt/conda/miniconda3/lib/python3.11/site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: pandas-datareader in /opt/conda/miniconda3/lib/python3.11/site-packages (0.10.0)\n",
            "Requirement already satisfied: lxml in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas-datareader) (5.3.0)\n",
            "Requirement already satisfied: pandas>=0.23 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas-datareader) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas-datareader) (2.31.0)\n",
            "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas>=0.23->pandas-datareader) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas>=0.23->pandas-datareader) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas>=0.23->pandas-datareader) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from pandas>=0.23->pandas-datareader) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests>=2.19.0->pandas-datareader) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests>=2.19.0->pandas-datareader) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests>=2.19.0->pandas-datareader) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/miniconda3/lib/python3.11/site-packages (from requests>=2.19.0->pandas-datareader) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=0.23->pandas-datareader) (1.17.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install fredapi\n",
        "! pip install yfinance\n",
        "! pip install pandas-datareader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b4ee8e1",
      "metadata": {
        "id": "9b4ee8e1"
      },
      "source": [
        "---\n",
        "# **Cluster set up**\n",
        "---\n",
        "\n",
        "```bash\n",
        "gcloud dataproc clusters create st446-cluster-final \\\n",
        "  --enable-component-gateway \\\n",
        "  --public-ip-address \\\n",
        "  --region=europe-west2 \\\n",
        "  --master-machine-type=n2-standard-2 \\\n",
        "  --master-boot-disk-size=100 \\\n",
        "  --num-workers=2 \\\n",
        "  --worker-machine-type=n2-standard-2 \\\n",
        "  --worker-boot-disk-size=200 \\\n",
        "  --image-version=2.2-debian12 \\\n",
        "  --optional-components=JUPYTER \\\n",
        "  --metadata='PIP_PACKAGES=lightgbm xgboost causalml scikit-learn pandas numpy matplotlib seaborn synapseml==0.11.1' \\\n",
        "  --initialization-actions='gs://st446-assignment-data/my_actions.sh' \\\n",
        "  --properties=^#^spark:spark.dynamicAllocation.enabled=false#spark:spark.jars.packages=ml.dmlc:xgboost4j-spark_2.12:1.6.1,com.microsoft.azure:synapseml_2.12:0.11.1 \\\n",
        "  --project=st446-wt2025-452419\n",
        "```\n",
        "\n",
        "\n",
        "### **Notes on Spark Properties**\n",
        "\n",
        "To specify multiple Spark properties in `--properties`, a custom separator (`^#^`) is used to avoid syntax conflicts with colons or commas in Maven artifact strings. This syntax ensures that both configuration settings and external packages (e.g., XGBoost and SynapseML) are correctly passed at cluster creation. Defining multiple `--properties` flags across lines is not supported; only the last occurrence will take effect."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "D6fsqeQcGEhp",
      "metadata": {
        "id": "D6fsqeQcGEhp"
      },
      "source": [
        "---\n",
        "## **IMPORTING LIBRARIES**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4509ef53",
      "metadata": {
        "id": "4509ef53"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import to_date, col, last, row_number\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "import pandas as pd\n",
        "from functools import reduce\n",
        "from fredapi import Fred\n",
        "import sqlite3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e76803b",
      "metadata": {
        "id": "8e76803b"
      },
      "source": [
        "---\n",
        "## **EXTRACTING MACROECONOMIC DATA USING API [FRED]**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a687a6ed",
      "metadata": {
        "id": "a687a6ed",
        "outputId": "bd0b87c9-a4d8-4ca9-eceb-11a2abc846fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/05/05 17:27:43 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+----------+-------------------+----+-----------------+------------+\n",
            "|      date|GDP Growth|                CPI| PMI|Unemployment Rate|Retail Sales|\n",
            "+----------+----------+-------------------+----+-----------------+------------+\n",
            "|1992-01-01|       4.9|  0.145032632342278|72.4|              7.3|    159177.0|\n",
            "|1992-04-01|       4.4|  0.143575017946859|71.7|              7.4|    159921.0|\n",
            "|1992-07-01|       4.0|0.21398002853068102|71.2|              7.7|    162855.0|\n",
            "|1992-10-01|       4.2|  0.353857041755123|70.5|              7.3|    166063.0|\n",
            "|1993-01-01|       0.7|0.49330514446792795|70.1|              7.3|    169500.0|\n",
            "|1993-04-01|       2.3|  0.278551532033427|69.5|              7.1|    172102.0|\n",
            "|1993-07-01|       1.9|                0.0|69.2|              6.9|    175822.0|\n",
            "|1993-10-01|       5.6|0.41350792556855703|68.6|              6.8|    177588.0|\n",
            "|1994-01-01|       3.9|  0.274348422496554|68.4|              6.6|    179615.0|\n",
            "|1994-04-01|       5.5|  0.135869565217392|67.9|              6.4|    186423.0|\n",
            "+----------+----------+-------------------+----+-----------------+------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Macroeconomic Indicators from FRED\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# SInitialize Fred API\n",
        "fred_key = 'e9bc109577b3480299a5db51dcb0969e'\n",
        "fred = Fred(api_key=fred_key)\n",
        "\n",
        "# Define indicators and FRED series IDs\n",
        "series_ids = {\n",
        "    'GDP Growth': 'A191RL1Q225SBEA',\n",
        "    'CPI': 'CPALTT01USM657N',\n",
        "    'PMI': 'CUUR0000SA0R',\n",
        "    'Unemployment Rate': 'UNRATE',\n",
        "    'Retail Sales': 'RSAFS'\n",
        "}\n",
        "\n",
        "start_date = '1992-01-01'\n",
        "end_date = '2025-01-04'\n",
        "\n",
        "# SFetch each series and merge\n",
        "dfs = []\n",
        "\n",
        "for indicator, series_id in series_ids.items():\n",
        "    try:\n",
        "        series_data = fred.get_series(series_id, observation_start=start_date, observation_end=end_date)\n",
        "        df = series_data.reset_index()\n",
        "        df.columns = [\"date\", indicator]\n",
        "        dfs.append(df)\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data for {indicator}: {e}\")\n",
        "\n",
        "df_combined = reduce(lambda left, right: pd.merge(left, right, on='date', how='outer'), dfs)\n",
        "\n",
        "# Convert to Spark DataFrame\n",
        "df_combined[\"date\"] = pd.to_datetime(df_combined[\"date\"])\n",
        "spark_df = spark.createDataFrame(df_combined)\n",
        "spark_df = spark_df.withColumn(\"date\", to_date(\"date\"))\n",
        "\n",
        "spark_df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f89c3698",
      "metadata": {
        "id": "f89c3698",
        "outputId": "5cb16ffe-fb8b-454b-91e3-87d2de2cdb74"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/05/05 17:27:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "25/05/05 17:27:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "25/05/05 17:27:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "25/05/05 17:27:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
          ]
        }
      ],
      "source": [
        "# Simulate backward fill using window functions\n",
        "bfill_window = Window.orderBy(col(\"date\").asc()).rowsBetween(0, Window.unboundedFollowing)\n",
        "\n",
        "# Identify columns to fill (excluding 'date')\n",
        "cols_to_fill = [c for c in spark_df.columns if c != \"date\"]\n",
        "\n",
        "# Apply backward fill column by column\n",
        "for c in cols_to_fill:\n",
        "    spark_df = spark_df.withColumn(c, last(c, ignorenulls=True).over(bfill_window))\n",
        "\n",
        "# Drop the last row using row number\n",
        "rownum_window = Window.orderBy(\"date\")\n",
        "spark_df_with_rownum = spark_df.withColumn(\"row_num\", row_number().over(rownum_window))\n",
        "\n",
        "# Get the last row number\n",
        "max_row = spark_df_with_rownum.agg({\"row_num\": \"max\"}).collect()[0][0]\n",
        "\n",
        "# Filter out the last row\n",
        "spark_df_trimmed = spark_df_with_rownum.filter(col(\"row_num\") < max_row).drop(\"row_num\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1bf6ef9",
      "metadata": {
        "id": "a1bf6ef9",
        "outputId": "1089082a-070a-4009-c8c0-0ff815c56d55"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/05/05 17:27:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "25/05/05 17:27:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "25/05/05 17:27:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "25/05/05 17:27:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "25/05/05 17:27:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully saved data to: gs://st446-data/economic_indicators_spark\n"
          ]
        }
      ],
      "source": [
        "# Write to a single CSV file in GCS\n",
        "output_path = \"gs://st446-data/economic_indicators_spark\"\n",
        "\n",
        "spark_df_trimmed.coalesce(1) \\\n",
        "    .write.option(\"header\", True) \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .csv(output_path)\n",
        "\n",
        "print(\"Successfully saved data to:\", output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "204a0613",
      "metadata": {
        "id": "204a0613"
      },
      "source": [
        "----\n",
        "## **SQL API EXTRACTION**\n",
        "\n",
        "[ extracting data using sql method ]\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65c280fa",
      "metadata": {
        "id": "65c280fa",
        "outputId": "396d7405-12f1-49fa-c42f-ee500f14eeaf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/05/05 17:27:52 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+------------------------+-----------------+---------------------------+----------------------------+---------------------+--------------+-------------+\n",
            "|      date|US Corporate as % of GDP|Net Export Growth|Industrial Production (IIP)|10-Year Government Bond Rate|Saving Rate of People|New Home Sales|FED Fund Rate|\n",
            "+----------+------------------------+-----------------+---------------------------+----------------------------+---------------------+--------------+-------------+\n",
            "|1992-01-01|                 329.803|          -20.536|                    61.4823|                        7.03|                  9.5|         676.0|         4.03|\n",
            "|1992-04-01|                 344.556|          -32.788|                    62.9199|                        7.48|                  9.8|         546.0|         3.73|\n",
            "|1992-07-01|                 328.651|          -38.488|                    63.7348|                        6.84|                  9.5|         627.0|         3.25|\n",
            "|1992-10-01|                 336.054|           -47.14|                    64.0178|                        6.59|                  7.9|         621.0|          3.1|\n",
            "|1993-01-01|                 334.638|          -55.704|                    64.6135|                         6.6|                  8.5|         596.0|         3.02|\n",
            "|1993-04-01|                 349.005|          -63.187|                    65.0423|                        5.97|                  8.7|         701.0|         2.96|\n",
            "|1993-07-01|                 362.106|          -68.354|                    65.1142|                        5.81|                  7.5|         655.0|         3.06|\n",
            "|1993-10-01|                 382.444|          -73.449|                     65.863|                        5.33|                  6.2|         704.0|         2.99|\n",
            "|1994-01-01|                 413.269|          -80.595|                    66.7591|                        5.75|                  7.0|         619.0|         3.05|\n",
            "|1994-04-01|                 427.525|          -90.572|                    67.8707|                        6.97|                  6.3|         692.0|         3.56|\n",
            "+----------+------------------------+-----------------+---------------------------+----------------------------+---------------------+--------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"FRED Macro Data\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Connect to FRED API\n",
        "fred_key = \"e9bc109577b3480299a5db51dcb0969e\"\n",
        "fred = Fred(api_key=fred_key)\n",
        "\n",
        "# Define series and date range\n",
        "series_ids = {\n",
        "    'US Corporate as % of GDP': 'CP',\n",
        "    'Net Export Growth': 'NETEXP',\n",
        "    'Industrial Production (IIP)': 'INDPRO',\n",
        "    '10-Year Government Bond Rate': 'IRLTLT01USM156N',\n",
        "    'Saving Rate of People': 'PSAVERT',\n",
        "    'New Home Sales': 'HSN1F',\n",
        "    'FED Fund Rate': 'FEDFUNDS'\n",
        "}\n",
        "\n",
        "start_date = '1992-01-01'\n",
        "end_date = '2025-01-04'\n",
        "\n",
        "# Fetch and merge data\n",
        "dfs = []\n",
        "\n",
        "for indicator, series_id in series_ids.items():\n",
        "    try:\n",
        "        series_data = fred.get_series(series_id, observation_start=start_date, observation_end=end_date)\n",
        "        df = series_data.reset_index()\n",
        "        df.columns = [\"date\", indicator]\n",
        "        dfs.append(df)\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data for {indicator}: {e}\")\n",
        "\n",
        "# Merge into one pandas DataFrame\n",
        "df_combined = reduce(lambda left, right: pd.merge(left, right, on='date', how='outer'), dfs)\n",
        "df_combined[\"date\"] = pd.to_datetime(df_combined[\"date\"])\n",
        "\n",
        "# Convert to Spark DataFrame\n",
        "spark_df = spark.createDataFrame(df_combined)\n",
        "spark_df = spark_df.withColumn(\"date\", to_date(\"date\"))\n",
        "\n",
        "\n",
        "# Show preview\n",
        "spark_df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dbf5cca",
      "metadata": {
        "id": "4dbf5cca",
        "outputId": "5b2a9414-d644-44c4-9cae-2869de67e7b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully inserted data into SQLite database.\n"
          ]
        }
      ],
      "source": [
        "# Convert Spark DataFrame to Pandas\n",
        "df_pandas = spark_df.toPandas()\n",
        "\n",
        "# Connect to SQLite\n",
        "conn = sqlite3.connect(\"fred_data.db\")\n",
        "\n",
        "# Save to SQLite\n",
        "df_pandas.to_sql(\"fred_data\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "print(\"Successfully inserted data into SQLite database.\")\n",
        "\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5c39194",
      "metadata": {
        "id": "c5c39194",
        "outputId": "6948e8f4-41a6-450b-db41-669e580a7a42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+------------------------+-----------------+---------------------------+----------------------------+---------------------+--------------+-------------+\n",
            "|      date|US Corporate as % of GDP|Net Export Growth|Industrial Production (IIP)|10-Year Government Bond Rate|Saving Rate of People|New Home Sales|FED Fund Rate|\n",
            "+----------+------------------------+-----------------+---------------------------+----------------------------+---------------------+--------------+-------------+\n",
            "|1992-01-01|                 329.803|          -20.536|                    61.4823|                        7.03|                  9.5|         676.0|         4.03|\n",
            "|1992-04-01|                 344.556|          -32.788|                    62.9199|                        7.48|                  9.8|         546.0|         3.73|\n",
            "|1992-07-01|                 328.651|          -38.488|                    63.7348|                        6.84|                  9.5|         627.0|         3.25|\n",
            "|1992-10-01|                 336.054|           -47.14|                    64.0178|                        6.59|                  7.9|         621.0|          3.1|\n",
            "|1993-01-01|                 334.638|          -55.704|                    64.6135|                         6.6|                  8.5|         596.0|         3.02|\n",
            "|1993-04-01|                 349.005|          -63.187|                    65.0423|                        5.97|                  8.7|         701.0|         2.96|\n",
            "|1993-07-01|                 362.106|          -68.354|                    65.1142|                        5.81|                  7.5|         655.0|         3.06|\n",
            "|1993-10-01|                 382.444|          -73.449|                     65.863|                        5.33|                  6.2|         704.0|         2.99|\n",
            "|1994-01-01|                 413.269|          -80.595|                    66.7591|                        5.75|                  7.0|         619.0|         3.05|\n",
            "|1994-04-01|                 427.525|          -90.572|                    67.8707|                        6.97|                  6.3|         692.0|         3.56|\n",
            "|1994-07-01|                  449.48|          -96.868|                    68.7317|                         7.3|                  6.9|         628.0|         4.26|\n",
            "|1994-10-01|                 463.129|         -101.913|                    69.9576|                        7.74|                  7.0|         715.0|         4.76|\n",
            "|1995-01-01|                 477.546|         -105.329|                    71.2635|                        7.78|                  7.3|         626.0|         5.53|\n",
            "|1995-04-01|                 501.314|         -109.492|                    71.1538|                        7.06|                  6.8|         621.0|         6.05|\n",
            "|1995-07-01|                 509.306|          -74.444|                    71.4334|                        6.28|                  6.9|         765.0|         5.85|\n",
            "|1995-10-01|                 516.952|           -69.78|                    72.5336|                        6.04|                  7.0|         696.0|         5.76|\n",
            "|1996-01-01|                 537.204|          -88.795|                    72.5712|                        5.65|                  6.5|         714.0|         5.56|\n",
            "|1996-04-01|                  540.29|          -93.709|                    74.2491|                        6.51|                  5.5|         736.0|         5.22|\n",
            "|1996-07-01|                 537.278|          -114.18|                    75.3738|                        6.87|                  6.5|         770.0|          5.4|\n",
            "|1996-10-01|                 550.942|          -88.822|                    76.2157|                        6.53|                  6.1|         720.0|         5.24|\n",
            "+----------+------------------------+-----------------+---------------------------+----------------------------+---------------------+--------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Reconnect to SQLite\n",
        "conn = sqlite3.connect(\"fred_data.db\")\n",
        "\n",
        "# SQL query to select desired columns\n",
        "query = \"\"\"\n",
        "SELECT\n",
        "    date,\n",
        "    \"US Corporate as % of GDP\",\n",
        "    \"Net Export Growth\",\n",
        "    \"Industrial Production (IIP)\",\n",
        "    \"10-Year Government Bond Rate\",\n",
        "    \"Saving Rate of People\",\n",
        "    \"New Home Sales\",\n",
        "    \"FED Fund Rate\"\n",
        "FROM fred_data\n",
        "\"\"\"\n",
        "\n",
        "# Load into pandas DataFrame\n",
        "df_extracted = pd.read_sql_query(query, conn)\n",
        "df_extracted[\"date\"] = pd.to_datetime(df_extracted[\"date\"])\n",
        "\n",
        "# Convert to Spark DataFrame\n",
        "spark_df_extracted = spark.createDataFrame(df_extracted)\n",
        "\n",
        "# Convert 'date' to Spark date type\n",
        "from pyspark.sql.functions import to_date\n",
        "spark_df_extracted = spark_df_extracted.withColumn(\"date\", to_date(\"date\"))\n",
        "\n",
        "# Use it in your pipeline\n",
        "spark_df_extracted.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e473988",
      "metadata": {
        "id": "3e473988"
      },
      "outputs": [],
      "source": [
        "spark_df_extracted = spark_df_extracted.withColumn(\"date\", to_date(\"date\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c844c6e",
      "metadata": {
        "id": "7c844c6e",
        "outputId": "18eaba4e-4c62-4ac6-a9e0-ca4c9853d956"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully saved this data to: gs://st446-data/economic_indicators_sql_spark\n"
          ]
        }
      ],
      "source": [
        "# Save to CSV (as a single file) in GCS bucket\n",
        "output_path = \"gs://st446-data/economic_indicators_sql_spark\"\n",
        "\n",
        "spark_df_extracted.coalesce(1) \\\n",
        "    .write.option(\"header\", True) \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .csv(output_path)\n",
        "\n",
        "print(\"Successfully saved this data to:\", output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29705a7c",
      "metadata": {
        "id": "29705a7c",
        "outputId": "2959ce8b-f99a-4b24-f267-0ca081bd96d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/05/05 17:28:00 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "25/05/05 17:28:00 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "25/05/05 17:28:00 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "25/05/05 17:28:01 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "25/05/05 17:28:01 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+------------------------+-----------------+---------------------------+----------------------------+---------------------+--------------+-------------+\n",
            "|      date|US Corporate as % of GDP|Net Export Growth|Industrial Production (IIP)|10-Year Government Bond Rate|Saving Rate of People|New Home Sales|FED Fund Rate|\n",
            "+----------+------------------------+-----------------+---------------------------+----------------------------+---------------------+--------------+-------------+\n",
            "|1992-01-01|                     NaN|        -1262.307|                   103.3418|                        4.63|                  3.9|         654.0|         4.33|\n",
            "|1992-02-01|                     NaN|        -1262.307|                   103.3418|                        4.63|                  3.9|         654.0|         4.33|\n",
            "|1992-03-01|                     NaN|        -1262.307|                   103.3418|                        4.63|                  3.9|         654.0|         4.33|\n",
            "|1992-04-01|                     NaN|        -1262.307|                   103.3418|                        4.63|                  3.9|         654.0|         4.33|\n",
            "|1992-05-01|                     NaN|        -1262.307|                   103.3418|                        4.63|                  3.9|         654.0|         4.33|\n",
            "|1992-06-01|                     NaN|        -1262.307|                   103.3418|                        4.63|                  3.9|         654.0|         4.33|\n",
            "|1992-07-01|                     NaN|        -1262.307|                   103.3418|                        4.63|                  3.9|         654.0|         4.33|\n",
            "|1992-08-01|                     NaN|        -1262.307|                   103.3418|                        4.63|                  3.9|         654.0|         4.33|\n",
            "|1992-09-01|                     NaN|        -1262.307|                   103.3418|                        4.63|                  3.9|         654.0|         4.33|\n",
            "|1992-10-01|                     NaN|        -1262.307|                   103.3418|                        4.63|                  3.9|         654.0|         4.33|\n",
            "|1992-11-01|                     NaN|        -1262.307|                   103.3418|                        4.63|                  3.9|         654.0|         4.33|\n",
            "|1992-12-01|                     NaN|        -1262.307|                   103.3418|                        4.63|                  3.9|         654.0|         4.33|\n",
            "|1993-01-01|                     NaN|        -1262.307|                   103.3418|                        4.63|                  3.9|         654.0|         4.33|\n",
            "|1993-02-01|                     NaN|        -1262.307|                   103.3418|                        4.63|                  3.9|         654.0|         4.33|\n",
            "|1993-03-01|                     NaN|        -1262.307|                   103.3418|                        4.63|                  3.9|         654.0|         4.33|\n",
            "|1993-04-01|                     NaN|        -1262.307|                   103.3418|                        4.63|                  3.9|         654.0|         4.33|\n",
            "|1993-05-01|                     NaN|        -1262.307|                   103.3418|                        4.63|                  3.9|         654.0|         4.33|\n",
            "|1993-06-01|                     NaN|        -1262.307|                   103.3418|                        4.63|                  3.9|         654.0|         4.33|\n",
            "|1993-07-01|                     NaN|        -1262.307|                   103.3418|                        4.63|                  3.9|         654.0|         4.33|\n",
            "|1993-08-01|                     NaN|        -1262.307|                   103.3418|                        4.63|                  3.9|         654.0|         4.33|\n",
            "+----------+------------------------+-----------------+---------------------------+----------------------------+---------------------+--------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define a backward-looking window (i.e., current row to the bottom)\n",
        "bfill_window = Window.orderBy(\"date\").rowsBetween(0, Window.unboundedFollowing)\n",
        "\n",
        "# Apply backward fill to all columns except 'date'\n",
        "columns_to_bfill = [c for c in spark_df_extracted.columns if c != \"date\"]\n",
        "\n",
        "# Fill each column using last() with ignorenulls=True\n",
        "for c in columns_to_bfill:\n",
        "    spark_df_extracted = spark_df_extracted.withColumn(\n",
        "        c, last(c, ignorenulls=True).over(bfill_window)\n",
        "    )\n",
        "\n",
        "# Show result\n",
        "spark_df_extracted.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "676e6fb1",
      "metadata": {
        "id": "676e6fb1",
        "outputId": "7f4522eb-93c8-454f-bae2-b25498d3a563",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+----------+---+----+-----------------+------------+------------------------+-----------------+---------------------------+----------------------------+---------------------+--------------+-------------+\n",
            "|      date|GDP Growth|CPI| PMI|Unemployment Rate|Retail Sales|US Corporate as % of GDP|Net Export Growth|Industrial Production (IIP)|10-Year Government Bond Rate|Saving Rate of People|New Home Sales|FED Fund Rate|\n",
            "+----------+----------+---+----+-----------------+------------+------------------------+-----------------+---------------------------+----------------------------+---------------------+--------------+-------------+\n",
            "|1992-01-01|      -0.3|NaN|31.5|              4.0|    711461.0|                 329.803|          -20.536|                    61.4823|                        7.03|                  9.5|         676.0|         4.03|\n",
            "|1992-04-01|      -0.3|NaN|31.5|              4.0|    711461.0|                 344.556|          -32.788|                    62.9199|                        7.48|                  9.8|         546.0|         3.73|\n",
            "|1992-07-01|      -0.3|NaN|31.5|              4.0|    711461.0|                 328.651|          -38.488|                    63.7348|                        6.84|                  9.5|         627.0|         3.25|\n",
            "|1992-10-01|      -0.3|NaN|31.5|              4.0|    711461.0|                 336.054|           -47.14|                    64.0178|                        6.59|                  7.9|         621.0|          3.1|\n",
            "|1993-01-01|      -0.3|NaN|31.5|              4.0|    711461.0|                 334.638|          -55.704|                    64.6135|                         6.6|                  8.5|         596.0|         3.02|\n",
            "|1993-04-01|      -0.3|NaN|31.5|              4.0|    711461.0|                 349.005|          -63.187|                    65.0423|                        5.97|                  8.7|         701.0|         2.96|\n",
            "|1993-07-01|      -0.3|NaN|31.5|              4.0|    711461.0|                 362.106|          -68.354|                    65.1142|                        5.81|                  7.5|         655.0|         3.06|\n",
            "|1993-10-01|      -0.3|NaN|31.5|              4.0|    711461.0|                 382.444|          -73.449|                     65.863|                        5.33|                  6.2|         704.0|         2.99|\n",
            "|1994-01-01|      -0.3|NaN|31.5|              4.0|    711461.0|                 413.269|          -80.595|                    66.7591|                        5.75|                  7.0|         619.0|         3.05|\n",
            "|1994-04-01|      -0.3|NaN|31.5|              4.0|    711461.0|                 427.525|          -90.572|                    67.8707|                        6.97|                  6.3|         692.0|         3.56|\n",
            "|1994-07-01|      -0.3|NaN|31.5|              4.0|    711461.0|                  449.48|          -96.868|                    68.7317|                         7.3|                  6.9|         628.0|         4.26|\n",
            "|1994-10-01|      -0.3|NaN|31.5|              4.0|    711461.0|                 463.129|         -101.913|                    69.9576|                        7.74|                  7.0|         715.0|         4.76|\n",
            "|1995-01-01|      -0.3|NaN|31.5|              4.0|    711461.0|                 477.546|         -105.329|                    71.2635|                        7.78|                  7.3|         626.0|         5.53|\n",
            "|1995-04-01|      -0.3|NaN|31.5|              4.0|    711461.0|                 501.314|         -109.492|                    71.1538|                        7.06|                  6.8|         621.0|         6.05|\n",
            "|1995-07-01|      -0.3|NaN|31.5|              4.0|    711461.0|                 509.306|          -74.444|                    71.4334|                        6.28|                  6.9|         765.0|         5.85|\n",
            "|1995-10-01|      -0.3|NaN|31.5|              4.0|    711461.0|                 516.952|           -69.78|                    72.5336|                        6.04|                  7.0|         696.0|         5.76|\n",
            "|1996-01-01|      -0.3|NaN|31.5|              4.0|    711461.0|                 537.204|          -88.795|                    72.5712|                        5.65|                  6.5|         714.0|         5.56|\n",
            "|1996-04-01|      -0.3|NaN|31.5|              4.0|    711461.0|                  540.29|          -93.709|                    74.2491|                        6.51|                  5.5|         736.0|         5.22|\n",
            "|1996-07-01|      -0.3|NaN|31.5|              4.0|    711461.0|                 537.278|          -114.18|                    75.3738|                        6.87|                  6.5|         770.0|          5.4|\n",
            "|1996-10-01|      -0.3|NaN|31.5|              4.0|    711461.0|                 550.942|          -88.822|                    76.2157|                        6.53|                  6.1|         720.0|         5.24|\n",
            "+----------+----------+---+----+-----------------+------------+------------------------+-----------------+---------------------------+----------------------------+---------------------+--------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Read both Spark-written CSVs from GCS\n",
        "df_fred = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"gs://st446-data/economic_indicators_spark/\")\n",
        "df_sql = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"gs://st446-data/economic_indicators_sql_spark/\")\n",
        "\n",
        "df_fred = df_fred.withColumn(\"date\", to_date(\"date\"))\n",
        "df_sql = df_sql.withColumn(\"date\", to_date(\"date\"))\n",
        "\n",
        "# Join both DataFrames on 'date' column (since Spark has no index)\n",
        "df_combined = df_fred.join(df_sql, on=\"date\", how=\"inner\")\n",
        "\n",
        "# Show result\n",
        "df_combined.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0093a116",
      "metadata": {
        "id": "0093a116",
        "outputId": "24f72bb5-e8e8-43e6-a601-876f913f8564"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Save to GCS temporary folder\n",
        "temp_path = \"gs://st446-data/tmp_st446_macro_data\"\n",
        "\n",
        "df_combined.coalesce(1) \\\n",
        "    .write.option(\"header\", True) \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .csv(temp_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tl6dias9HC2d",
      "metadata": {
        "id": "tl6dias9HC2d"
      },
      "source": [
        "---\n",
        "## **EXTRACTING FUNDAMENTAL DATA FROM BLOOMBERG**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b62a4c50",
      "metadata": {
        "id": "b62a4c50"
      },
      "source": [
        "---\n",
        "\n",
        "#### Here, we select our required parameters based on our objective and download the dataset.\n",
        "\n",
        "#### We download the `st446_macro_data.csv` from the bucket, uploading the `st446_trading_and_fundamental_data_bbg.csv`- download from Bloomberg, and merging the data.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26b0ccc7",
      "metadata": {
        "id": "26b0ccc7"
      },
      "source": [
        "---\n",
        "### **MERGING THE DATA**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d876ae7",
      "metadata": {
        "id": "4d876ae7",
        "outputId": "912a7995-6206-42e5-b3ce-bfac7e20f6ea",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Create Spark session\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# Set your bucket name\n",
        "bucket = 'st446-data'\n",
        "\n",
        "# Define file paths\n",
        "fundamental_path = f'gs://{bucket}/st446_trading_and_fundamental_data_bbg.csv'\n",
        "macro_path = f'gs://{bucket}/st446_macro_data.csv'\n",
        "\n",
        "# Read CSV files into DataFrames\n",
        "fundamental_df = spark.read.csv(fundamental_path, header=True, inferSchema=True)\n",
        "macro_df = spark.read.csv(macro_path, header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb45df15",
      "metadata": {
        "id": "eb45df15"
      },
      "outputs": [],
      "source": [
        "macro_df = macro_df.withColumnRenamed('date', 'macro_date')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "809330b6",
      "metadata": {
        "id": "809330b6"
      },
      "outputs": [],
      "source": [
        "data_df = fundamental_df.join(macro_df, on='month', how='left')\n",
        "data_df = data_df.drop('macro_date', 'month','quarter','year','px_last','cur_mkt_cap','logret','spx_logret')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02bb3d91",
      "metadata": {
        "id": "02bb3d91",
        "outputId": "c9f15441-f4a0-4ea2-d283-d05f6cc0be5d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 72:=============================>                            (1 + 1) / 2]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows with at least one NULL: 91\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Count rows that have any nulls\n",
        "null_rows = data_df.filter(\n",
        "    sum(col(c).isNull().cast(\"int\") for c in data_df.columns) > 0\n",
        ")\n",
        "\n",
        "# Show how many rows have at least one NULL\n",
        "print(\"Number of rows with at least one NULL:\", null_rows.count())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07dad41a",
      "metadata": {
        "id": "07dad41a"
      },
      "outputs": [],
      "source": [
        "data = data_df.dropna(how='any')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc47cfd0",
      "metadata": {
        "id": "dc47cfd0"
      },
      "outputs": [],
      "source": [
        "# Filter the data of SPX index\n",
        "data = data.filter(data.stock != 'SPX Index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9428a800",
      "metadata": {
        "id": "9428a800",
        "outputId": "4113a45e-4c23-45f0-d80c-c482ca173a38"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 76:=============================>                            (1 + 1) / 2]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame shape: (146165, 44)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "\n",
        "n_rows = data.count()\n",
        "\n",
        "n_cols = len(data.columns)\n",
        "\n",
        "print(f\"DataFrame shape: ({n_rows}, {n_cols})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff02bf33",
      "metadata": {
        "id": "ff02bf33",
        "outputId": "fb093f3c-a421-4854-95ea-1de411195586",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "[Stage 80:>                                                         (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------+-----+----------------+---------+-----------+----------+-------------------+---------------------+-----------------------+------------+-----------+-----------+---------------+--------------+--------------+-------------+------------------------------+-------------+--------+----------------+-----------------+--------------+---------+---------------+--------------+------------+------------+-------------------+------------------+------------------+----------------+---------------+----------+----+-----------------+------------+-----------------+----------------------------+---------------------+--------------+-------------+------------+----------+\n",
            "|stock|date      |score|market_cap_score|cur_ratio|quick_ratio|cash_ratio|tot_debt_to_tot_eqy|tot_debt_to_tot_asset|interest_coverage_ratio|gross_margin|oper_margin|prof_margin|return_on_asset|return_com_eqy|asset_turnover|acct_rcv_turn|accounts_payable_turnover_days|acct_rcv_days|pe_ratio|px_to_book_ratio|px_to_sales_ratio|dividend_yield|ev_ebitda|px_to_cash_flow|net_inc_growth|sales_growth|asset_growth|total_equity_growth|total_assets_score|total_equity_score|net_income_score|net_sales_score|gdp_growth|cpi |unemployment_rate|retail_sales|net_export_growth|10_year_government_bond_rate|saving_rate_of_people|new_home_sales|fed_fund_rate|pmi_minus_50|iip_growth|\n",
            "+-----+----------+-----+----------------+---------+-----------+----------+-------------------+---------------------+-----------------------+------------+-----------+-----------+---------------+--------------+--------------+-------------+------------------------------+-------------+--------+----------------+-----------------+--------------+---------+---------------+--------------+------------+------------+-------------------+------------------+------------------+----------------+---------------+----------+----+-----------------+------------+-----------------+----------------------------+---------------------+--------------+-------------+------------+----------+\n",
            "|A    |30/06/1998|5.0  |5               |1.66     |0.77       |0.36      |13.76              |8.51                 |2.14                   |46.27       |3.56       |2.84       |3.5            |5.54          |1.23          |6.08         |44.89                         |59.99        |22.33   |1.11            |0.59             |0.31          |8.04     |8.71           |-51.84        |15.43       |10.16       |11.93              |4.0               |4.0               |4.0             |4.0            |5.1       |0.12|4.5              |0.01        |6.86             |5.5                         |6.5                  |0.04          |5.56         |1           |-0.59     |\n",
            "|A    |31/07/1998|5.0  |5               |1.66     |0.77       |0.36      |13.76              |8.51                 |2.14                   |46.27       |3.56       |2.84       |3.5            |5.54          |1.23          |6.08         |44.89                         |59.99        |22.33   |1.11            |0.59             |0.31          |8.04     |8.71           |-51.84        |15.43       |10.16       |11.93              |4.0               |4.0               |4.0             |4.0            |5.1       |0.12|4.5              |-0.01       |6.81             |5.46                        |6.6                  |-0.05         |5.54         |1           |-0.4      |\n",
            "|A    |31/08/1998|1.0  |5               |1.66     |0.77       |0.36      |13.76              |8.51                 |2.14                   |46.27       |3.56       |2.84       |3.5            |5.54          |1.23          |6.08         |44.89                         |59.99        |22.33   |1.11            |0.59             |0.31          |8.04     |8.71           |-51.84        |15.43       |10.16       |11.93              |4.0               |4.0               |4.0             |4.0            |6.6       |0.12|4.5              |-0.0        |6.86             |5.34                        |6.5                  |-0.03         |5.55         |1           |2.06      |\n",
            "|A    |30/09/1998|5.0  |5               |2.4      |1.07       |0.58      |0.0                |0.0                  |2.14                   |40.82       |-9.41      |2.15       |2.19           |3.3           |1.02          |5.28         |49.56                         |69.19        |25.35   |1.56            |1.05             |0.31          |8.04     |5.65           |-76.22        |-13.72      |-5.21       |7.48               |4.0               |4.0               |3.0             |4.0            |6.6       |0.12|4.6              |0.01        |6.86             |4.81                        |6.1                  |0.02          |5.51         |1           |-0.09     |\n",
            "|A    |30/10/1998|1.0  |5               |2.4      |1.07       |0.58      |0.0                |0.0                  |2.14                   |40.82       |-9.41      |2.15       |2.19           |3.3           |1.02          |5.28         |49.56                         |69.19        |25.35   |1.56            |1.05             |0.31          |8.04     |5.65           |-76.22        |-13.72      |-5.21       |7.48               |4.0               |4.0               |3.0             |4.0            |6.6       |0.24|4.5              |0.02        |6.8              |4.53                        |5.9                  |0.03          |5.07         |1           |0.68      |\n",
            "+-----+----------+-----+----------------+---------+-----------+----------+-------------------+---------------------+-----------------------+------------+-----------+-----------+---------------+--------------+--------------+-------------+------------------------------+-------------+--------+----------------+-----------------+--------------+---------+---------------+--------------+------------+------------+-------------------+------------------+------------------+----------------+---------------+----------+----+-----------------+------------+-----------------+----------------------------+---------------------+--------------+-------------+------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "data.show(5,truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "056b0033",
      "metadata": {
        "id": "056b0033"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "PySpark",
      "language": "python",
      "name": "pyspark"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
